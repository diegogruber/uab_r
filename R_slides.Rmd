---
title: "Intro to Data Analysis with R"
author: "Diego Gruber"
date: "April 4-6, 2016"
output: 
  ioslides_presentation: 
    fig_height: 4
    fig_width: 4
    logo: img/idea_logo.png
    widescreen: yes
---

```{r setup, include=FALSE}
library(knitr)
library(data.table)
library(ggplot2)
library(magrittr)
library(tidyr)
opts_chunk$set(echo = FALSE, fig.align = 'center')
```

## Objectives

This **is not** intended as a course on statistical methods or econometric techniques! 

Instead, you will learn how to 

- Explore, groom, visualize, and analyze data 
- Make your code reproducible, reusable, and shareable 
- Improve the efficiency and enjoyability of your workflow

## Outline

1. An overview of the R ecosystem
2. Data visualization
3. Data wrangling
4. Data Analysis

The R Ecosystem
===============

## R

- A programming language and software environment
- Created by Ross Ihaka and Robert Gentleman
    - 1993: Research project in Auckland, NZ  
    - 1995: R Released as **open-source software**
    - 1997: R core group formed...
    - 2000: R 1.0.0 released
- Designed for statistical analysis and graphics
    - As opposed to general purpose language, such as Python
- Published under GNU license -> **Open source!**
 
## R - Extensibility

- Capabilities of R are extended through **user-created packages**
- Packages are mainly hosted on **[CRAN](https://cran.r-project.org)**
    - quality and licensing requirements
    - core group volunteers and automated testing
- Other popular repositories:
    - Bioconductor (for bioinformatics)
    - Github (mostly for development)
    
## R - Extensibility

<div style="text-align:center">
<img src = "img/cran_packages.png" width = "800"> <br>
<a href = "http://blog.revolutionanalytics.com/2016/03/16-years-of-r-history.html"> Find out more </a>
</div>
    
## R - Popularity

<div style="text-align:center">
<img src = "img/tiobe.png" width = "650"> <br>
<a href = "http://blog.revolutionanalytics.com/popularity/"> Find out more </a>
</div>

## RStudio

- Free and open source [IDE for R](www.rstudio.com)
- Desktop and Server
- **Panes**: Code Editor, Console, Debugger, Plots, Viewer, Packages...
- **Cheatsheets!**
- **Options** (Tip: turn off automatic save / load of your last session)
- **Projects**: Great way to organize your work
- **Packages**: Become an R developer
- You can now create [extensions for RStudio](https://github.com/daattali/rstudio-addins#readme)

## RMarkdown

- **Markdown** is a text-to-HTML conversion tool developed by John Gruber (no relation!)
- Write in an easy-to-read, easy-to-write plain text format, then convert to HTML
- **RMarkdown**: Combine Markdown with *R-chunks*
- Quick reference in RStudio + Great [documentation](http://rmarkdown.rstudio.com)
- Also supported: **LaTeX!**
- Other output formats: PDF, Word, Github, etc...
- **Reproducible Research:** full computational environment required to reproduce results in a research paper (data, code...)

## Version Control

![Many many versions](img/paper_versions.png)

## Version Control

- **Keep track of changes** in your project
- **Backup** your files and restore previous versions
- Maintain **multiple versions**, eventually merge them
- **Collaborate** with people
- **Share** your work with the world

## Git

- Git is a decentralized version control system
- Created by Linus Torvalds
- Current standard in software development
- Command line or GUI
    - RStudio
    - Sourcetree
- Remote repository services
    - Github
    - Bitbucket
  
## Git Repository Structure

![Git Repository Structure](img/git_repository.png)

## Basic Git commands

For this class...

- clone
- status
- add
- commit
- push
- pull

Learn more at [Codecademy](https://www.codecademy.com/learn/learn-git)

## Clone these slides

To download this slides you can use the command line:

```
git clone https://github.com/diegogruber/uab_r
```

or from RStudio:

1. File / New Project / Version Control / Git
2. Enter the [repository URL](https://github.com/diegogruber/uab_r), directory, and destination

To generate the HTML file, open the .Rmd file in RStudio and press the *Knit HTML* button.

To update the repository when there is a new commit type `git pull` in the command line or press the *pull* button in RStudio.

Data Visualization
==================

## Why visualize

- Things we typically look for in data:
    - Trends
    - Gaps
    - Outliers
- We're well equipped for visual analysis
    - High bandwidth input device: our eyes
    - Powerful CPU with sophisticated image-recognition algorithms: our brains.
- Information => Interpretation => Action

## Anscombe's Quartett

Four sets of `(x,y)` pairs, quick inspection hardly reveals any differences...

```{r, results='asis'}
anscombe_tidy <- anscombe %>%
  data.table %>% .[, obs := 1:.N] %>% 
  gather(key, value, -obs) %>%
  separate(key, c("variable", "set"), 1, convert = TRUE) %>% 
  data.table %>% .[, set := LETTERS[set]] %>%
  spread(variable, value)

anscombe_tidy %>% 
  dcast.data.table(obs~set, value.var = c("x", "y")) %>% 
  tail(5) %>% 
  kable(align = "c")
```

## Anscombe's Quartett

Comparing some basic statistics, differences appear to be minimal...

```{r, results='asis', size="small"}
anscombe_tidy[, .(
  mean = mean(y),
  var = var(y),
  corr = cor(x, y),
  reg_coef_a = lm(y ~ x)$coefficients[1],
  reg_coef_b = lm(y ~ x)$coefficients[2]
), by = set] %>% 
  kable(digits = 2, align = "c")
```

## Anscombe's Quartett

Yet visual inspection quickly reveals the differences!

```{r, fig.width=10, fig.height=5}
anscombe_tidy %>% ggplot(aes(x, y)) + 
  facet_wrap(~set) + 
  geom_point() + 
  geom_smooth(method = lm, se = F) +
  theme_bw()
```

## Visualization in a data analysis workflow

- Explore
- Iterate
- Communicate

## Outline

- A grammar of graphics
- ggplot2
- Best practices

## Grammar of graphics

> **Grammar:** The basic elements of an area of knowledge or skill (Oxford Online)

- A grammar will let us answers questions such as:
    - What is a graphic?
    - How do you describe a graphic?
    - How do you create a graphic?
- References:
    - Wilkinson, Anand, and Grossman (2005), *The Grammar of Graphics*
    - Wickham (2010), *A Layered Grammar of Graphics*

## Elements

- A graphic is made out of one or more **layers**
- Each layer consists of a series of **elements**:
    - Data
    - A **geometry** and related **positioning** of its components
    - A **mapping** between the data and the aesthetic components of the selected geometry
    - A **facetting** scheme
    - A **scale** and a **coordinate system**
    - A **statistical transformation**
    - Annotations
- We will now explore each in detail

## Data

We need to generate some simple data for our example...

```{r results='asis'}
mydata <- data.table(
  A = c(2,1,4,9),
  B = c(3,2,5,10),
  C = c(4,1,15,80),
  D = c("a", "a", "b", "b")
)
kable(mydata, align = "c")
```

## Geometry

- A *geom* refers to the basic shapes of our graphic (points, lines, bars, etc.)
- Each geom has a set of aesthetic elements
- Some geoms can have different ways of positioning these elements (e.g. stacked bars vs. contiguous bars)
- Let's draw a *scatter plot*. We need to define the following properties:
    - **Horizontal position**
    - **Vertical position**
    - Shape
    - Size
    - Color
    - ...
  
## Mapping data to aesthetics

Let's connect our data to the aesthetics of the selected geom:

- Variable `A` to the horizontal position
- Variable `C` to the vertical position
- Variable `D` to point shape

```{r}
mydata[ , `:=`(x = A, y = C, Shape = D), by = .()]
kable(mydata[, .(x, y, Shape)], align = "c")
```

## Faceting

- Separate panels representing subsets of data
- No faceting for this simple example, will come back to it later

## Scales

- Transform variable values to units that can be represented on the screen or paper
- Each aesthetic property requires a scale (e.g. an axis or a legend).
- Example: transform `x` with a linear scale:
$$\text{floor}\left(\frac{x - \min(x)}{\text{range}(x)}\times\text{[screen width]}\right)$$
- Shape mapping:
    - Group "a": circle
    - Group "b": square

## Scales 

Suppose we wished to map values of `x` to the range [0,200] and values of `y` to the range [0,300]. Our data take the following values:
```{r}
myscale <- function(var, space) {
  floor((var - min(var))/diff(range(var))*diff(range(space))) + min(space)
}
mydata[ , `:=`(
  x = myscale(x, c(0, 200)), 
  y = myscale(y, c(0, 300)), 
  Shape = ifelse(Shape == "a", "circle", "square")
), by = .()]
kable(mydata[, .(` ` = D, x, y, Shape)], align = "c")
```

## Statistical Transformation

- Rescaled data can be transformed by a statistic function (a *stat*):
    - Mean
    - Median
    - Regression
    - Density
    - Etc.
- Transformation must be scale invariant:
$$f(x + a) = f(x) + a \qquad \text{y} \qquad f(b \cdot x) = b \cdot f(x)$$
- For this example the most basic transformation: Identity

## Coordinate System

- Coordinate systems change the appearance of a graphic 
- We only consider Cartesian plane
- Other systems:
  - Geodesic projections are important when working with cartographic data
  - Polar coordinates
  - Mosaics
  - Etc.

## Annotations 

- Elements that hep us with the interpretation of a graphic:
    - Titles
    - Grids
    - Etc.

## Basic example: Result

```{r}
basic_plot <- mydata %>% ggplot(aes(x = A, y = C)) + 
  layer(
    mapping = aes(shape = D), 
    geom = "point", 
    stat = "identity",
    position = "identity",
    params = list(size = 8, na.rm = TRUE)) + 
  scale_shape_manual(values = c(16, 15)) + 
  scale_x_continuous(labels = NULL) +
  scale_y_continuous(labels = NULL) +
  ggtitle("Title") + 
  theme_classic() + theme(legend.position = "none")
basic_plot
```

## Faceting

Add some complexity partitioning by variable D:

```{r fig.width=7}
basic_plot + facet_grid(~D)
```

## Multiple Layers

- Graphics can have multiple layers
- In general, the elements described so far can be described on a per-layer basis, except:
    - Faceting
    - Coordinate system
- Often, layers share several common elements.
- Add a layer of lines to our plot... 

## Multiple Layers

```{r}
basic_plot + layer(
  geom = "smooth", 
  stat = "smooth", 
  position = "identity",
  params = list(method = lm, se = F, color = "blue", na.rm = TRUE))
```

Statistical transformation: linear regression


Implementation in ggplot2
=========================

## Introduction

- A good implementation of the grammar of graphics should meet certain criteria:
    - Syntax related to elements of the grammar
    - Avoid redundant code
    - Good defaults for each element
    - Ample selection of geoms, stats, scales, etc.
- Success has led to clones in other programming languages (e.g.. ggplot en Python)
- Reference: [ggplot2 documentation](http://docs.ggplot2.org/current/)

## ggplot2 - Quick start

- Every ggplot2 graph begins with the function `ggplot()`
- Add layers using the `+` operator and the `layer()` function
- For each layer specify
    - data (`data = ...`)
    - geometry (`geom = ...`) and its position (`position = ...`)
    - a mapping from variables to aesthetic elements `mapping = aes(...)`
    - a statistical transformation (`stat = ...`)
    - other options through `params = list(...)`
- ggplot2 automatically selects a scale based on variable type and range
- Let's see how we produced the previous plot...

## ggplot2 - Quick start

```{r echo=TRUE}
myplot1 <- ggplot() + 
  layer(
    data = mydata, 
    geom = "point", position = "identity",
    mapping = aes(x = A, y = C, shape = D), 
    stat = "identity",
    params = list(na.rm = TRUE, size = 8)) +
  layer(
    data = mydata, 
    geom = "smooth", position = "identity",
    mapping = aes(x = A, y = C), 
    stat = "smooth",
    params = list(na.rm = TRUE, method = lm, se = F, color = "blue"))
```

## ggplot2 - Quick start

```{r fig.width=6}
myplot1
```

## ggplot2 - Plot defaults

Our previous specification has many redundancies. The `ggplot` function may be used to specify defaults:

```{r echo=TRUE}
myplot2 <- ggplot(data = mydata, mapping = aes(x = A, y = C)) + 
  layer(
    geom = "point", position = "identity",
    mapping = aes(shape = D), 
    stat = "identity",
    params = list(na.rm = TRUE, size = 8)) +
  layer(
    geom = "smooth", position = "identity",
    stat = "smooth",
    params = list(na.rm = TRUE, method = lm, se = F, color = "blue"))
```

## ggplot2 - Plot defaults

```{r fig.width=6}
myplot2
```

## ggplot2 - Shortcuts

- Functions `geom...` and `stat...` indicate directly the desired geom and statistical transformation
- Each of these function has carefully selected defaults
    - Each `geom` has an associated stat by default
    - Each `stat` is associated to a geom by default
- Each shortcut function has its own parameters

```{r echo=TRUE}
myplot3 <- ggplot(data = mydata, mapping = aes(x = A, y = C)) + 
  geom_point(mapping = aes(shape = D), size = 8) +
  stat_smooth(method = lm, se = F)
```

## ggplot2 - Shortcuts

```{r fig.width=6}
myplot3
```

## ggplot2 - Incremental graphics

Add complexity without repeating code:

```{r echo=TRUE, fig.height = 3, fig.width=8}
myplot3 + facet_grid(~D)
```

## ggplot2 - Modifying scale and appearance

- Modify scales with the `scale...` functions
- Modify appearance with the `theme...` functions
- Other functions help adding titles and other elements:

```{r echo=TRUE}
myplot4 <- myplot3 + 
  scale_shape_manual(values = c(16, 15)) + 
  scale_x_continuous(breaks = seq(0, 10, 2)) +
  scale_y_continuous(limits = c(0, 100)) +
  ggtitle("Title") + 
  theme_classic() + theme(legend.position = "none")
```

## ggplot2 - Modifying scale and appearance

```{r, message=FALSE, warning=FALSE}
myplot4
```

## Other packages

- Modify units (percentages or currency) with **scales**
- Create arbitrary array of plots with **gridExtra**
- More themes (Economist, WSJ, 538, Excel97...) with **ggthemes**
- Improve coloring with the **viridis** and **RColorBrewer** palettes
- Turn ggplots into interactive html graphics with **plotly**
- Etc. Check out 

## ggplot2 add-ins

- Version 2 introduced an API to create your own geoms
- Check out the [ggplot2 extensions repository](http://www.ggplot2-exts.org/gganimate.html)

## From grammar to 'poetry'

- The grammar of graphics lets you understand the elements that make up a data visualization and how they relate to each other
- In language, knowing grammar does not a good writer make.
- Likewise, you may know gg and still create hideous graphics that are hard to interpret
- To make good graphics you must know how to choose:
    - The appropriate geom, scale, and mapping
    - An adequate statistical transformation
    - Add annotations that clarify and simplify
    - Make it look nice to the eye

A nicer example
===============

```{r}
opts_chunk$set(fig.width = 8)
```

## Data

```{r, results='asis'}
library(gapminder)
gapminder %>% 
  head(5) %>% 
  kable(digits = 2)
```

## Base plot

```{r echo=TRUE}
gmplot <- ggplot(
  data = subset(gapminder, year == 2007), 
  aes(
    x = gdpPercap, 
    y = lifeExp, 
    color = continent))  +
    geom_point(aes(size = pop, text = country))
```

## Base plot

```{r}
gmplot
```

## Modifying scales and appearance

```{r echo=TRUE}
library(RColorBrewer)
gmplot <- gmplot +
  # logarithmic scale
  scale_x_log10(
    breaks = c(1000, 5000, 10000, 25000, 50000),
    labels = scales::dollar) +
  # nicer colors 
  scale_color_brewer(palette = "Set1", name = "Continent") +
  # Annotations
  scale_size_area(name = "Population") +
  xlab("GDP per capita") + 
  ylab("Life Expectancy") +
  # theme 
  theme_bw()
```

## Modifying scales and appearance

```{r}
gmplot
```

## Adding a layer

```{r echo=TRUE}
# In October 2015, the World Bank updated the international poverty line to
# US$1.90 a day
poverty_line <- 365 * 1.90
gmplot <- gmplot + 
  geom_vline(
    aes(xintercept = poverty_line),
    color = "red",
    linetype = 2)
```

## Adding a layer

```{r}
gmplot
```

## Text labels

```{r echo=TRUE}
gmplot + geom_text(aes(label = country))
```

## Text labels - ggrepel

```{r echo=TRUE}
library(ggrepel)
gmplot +  geom_label_repel(aes(label = country))
```

## Text labels - ggrepel

```{r echo=TRUE}
gmplot +  geom_label_repel(
    data = subset(gapminder, year == 2007 & pop > 100e6), 
    aes(label = country))
```

## Interactivity

```{r echo=TRUE, message=FALSE, warning=FALSE, echo=TRUE}
library(plotly)
gmplotly <- ggplotly(gmplot, tooltip = c("text", "size", "x", "y"))
```

## Interactivity

```{r}
gmplotly
```


Data wrangling
==============

```{r}
opts_chunk$set(echo = TRUE)
```

## Intro

- For any visualization or analysis task, you need your data in a certain shape
- Most of the time, your data is not how you need it
- R has some great tools to reshape your data
    - The data.table package
    - The dplyr and tidyr packages
    
## Different approaches    
    
```{r, echo=FALSE, results='as.is'}
data.frame(
  Approach = c("Base R", "data.table", "dplyr + tidyr"),
  Syntax = c("Cumbersome", "Nice", "Nicer"),
  Speed = c("Meh", "Very fast", "Fast"),
  Use_in_functions = c("Straightforward", "Doable", "Tricky"),
  Use_with_databases = c("No", "No", "Yes")
) %>% kable()
```

We'll focus on data.table, but dplyr is also worth checking out.

## The *data.table* package

- Created by Matt Dowle for high performance data wrangling in R
- Aggregate large data and perform ordered joins blazingly fast
- Add/modify/delete columns by group using no copies at all 
- Natural and flexible syntax that: faster development compared to base R 

```{r}
library(data.table)
options(datatable.print.topn = 3) 
# display only first and last 3 rows of data when printing
```

## Creating *data.table* objects

- Create an object from scratch with the `data.table` function
- Convert a data frame to a data table with the `as.data.table` function
- Import a data table from a text file using `fread`

```{r}
library(hflights)
hflights_dt <- data.table(hflights)
```

- The `data.table` class inherits from `data.frame` (use your data tables as data frames)

```{r}
is.data.frame(hflights_dt)
```

## Syntax

Operate with the data table by specifying `DT[i, j, by]`, where 

- `i` selects rows (the `WHERE` clause)
- `j` selects columns (the `SELECT` clause)
    - alternatively, using the `:=` operator updates the table by reference (`UPDATE` clause)
- `by` defines subsets for operations in `j` (the `GROUP BY` clause)
    - alternatively, `keyby` groups and orders

## Subsetting

Select rows by index and columns by list of names: 

```{r echo=TRUE}
hflights_dt[3:5, .(UniqueCarrier, Origin, Dest)]
```

## Subsetting

Pick columns by index or character vector using `with = FALSE`:

```{r}
hflights_dt[3:5, c(7,14,15), with = FALSE]
```

## Subsetting

Select rows by condition:

```{r}
hflights_dt[Dest == "BPT", .(UniqueCarrier, Origin, Dest)]
```

## Performance comparison

Data frame:

```{r}
system.time(hflights[hflights $ Dest == "BPT",])
```

Data table:

```{r}
system.time(hflights_dt[Dest == "BPT"])
```

## Create new column

- New column with year, month, and day of flight in a single variable
- The `paste` function lets you concatenate strings.

```{r}
(hf_sub <- hflights_dt[3:5, .(
  UniqueCarrier, 
  Origin, 
  Dest, 
  date = paste(Year, Month, DayofMonth, sep = "-"))])
```

## Sorting

Set a *key* using `setkey` or `setkeyv` for sorting:

```{r}
setkey(hf_sub, date)
hf_sub
```

## Assign by reference

- Use the `:=` function in `j` instead of `.`
- This modifies the object permanently (creates no copies)

```{r, results='hide'}
hflights_dt[, `:=`(Origin = tolower(Origin))]
```

```{r}
hflights_dt[3:5, .(UniqueCarrier, Origin, Dest)]
```

## Summarizing

Summarize data for the entire table:

```{r}
hflights_dt[, .(                         
  dep_delay = mean(DepDelay, na.rm = TRUE),
  arr_delay = mean(ArrDelay, na.rm = TRUE)
)]
```

## Summarizing

Summarize by group:

```{r}
hflights_dt[, .(                    
  dep_delay = mean(DepDelay, na.rm = TRUE),  
  arr_delay = mean(ArrDelay, na.rm = TRUE)
), keyby = .(Origin)]
```

## Keyword .N

- Keywords `.N` and `.SD` are very useful when operating by groups 
- `.N` is the number of observations in each by-group, used to perform frequency counts
- Example: use `.N` to calculate percentage of cancelled flights by airport, rounded:

```{r}
hflights_dt[, .(.N, pct_cancelled = round(100*sum(Cancelled)/.N, 2)), by = Origin]
```

## Keyword .SD

- `.SD` is a shorthand for the subset of data corresponding to the by-group
- Example: R-squared of fitting a linear regression between arrival and departure delays by airport of origin:

```{r}
rsq <- function(x){
  lm(ArrDelay ~ DepDelay, data = x) %>% # run regression
  summary() %>%  # compute statistics
  `$`(r.squared) # extract r-squared
}
hflights_dt[, .(r_squared = rsq(.SD)), by = Origin]
```

## Merging data tables

Create two tables:
- Number of cancellations by month
- Number of cancellations by month and airport of origin, only for the first half of the year:

```{r}
cancel_month <- hflights_dt[
  , .(cancel_tot = sum(Cancelled))
  , keyby = Month]
cancel_orig  <- hflights_dt[
  Month %in% 1:6
  , .(cancel_orig = sum(Cancelled))
  , keyby = .(Origin, Month)]
```

## Merging data tables

```{r}
merge(cancel_orig, cancel_month, by = "Month") # Merge by month
```

## Reshaping data tables

```{r}
last_month <- 3
(fdur <- hflights_dt %>% .[
  AirTime > 0 & Month %in% 1:last_month
  , .(total_airtime = round(sum(AirTime)))
  , keyby = .(Month, TailNum)])
```

## Casting

Spread a column into many columns:

```{r}
(fdur_cast <- fdur %>% dcast.data.table(
  TailNum ~ month.name[Month], # row ids ~ column ids
  value.var = "total_airtime", # vars to spread
  fill = 0)) # missing values take this value
```

## Melting

Collapse many columns into one:

```{r}
fdur_cast %>% melt(
  id.vars = "TailNum", # don't melt this variable
  variable.name = "Month", # put the column names here
  value.name = "Airtime") # put the values here
```


Programming
===========

## Control structures

- So far our code was *sequential*
- But many applications require more complex execution flows:
    - conditional structures (*if* this *then* that) 
    - loops
    - functions

## Conditionals

Execute code only if some logical condition holds (and do something else if it doesn't).

```{r, eval=FALSE}
if (condition) { 
  code to execute if condition holds
} else {
  code to execute if condition does not hold
}
```

The condition must give a `TRUE` or `FALSE` value.

## `for` and `while` loops

A `for` loop runs expressions a fixed number of times.

```{r, eval=FALSE}
for (symbol in sequence) { 
    expressions 
} 
```

A `while` loop runs expressions until a condition is met:

```{r, eval=FALSE}
while (condition) { 
  expression
  update(condition)  
} 
```

Loops in R tend to be inefficient. Whenever possible, *vectorize* your operations!

## The *apply* family of functions

`apply` functions are an alternative to loops. Instead of this

```{r}
a1 <- list()
length(a1) <- ncol(mtcars)
names(a1) <- names(mtcars)
for(i in 1:ncol(mtcars)) {
  a1[i] <- mean(mtcars[[i]])
}
```

You can do this

```{r}
a2 <- lapply(mtcars, mean)
```

Similar functions: apply, sapply, tapply, vapply, ...

## Parallel computing

- Base R only takes advantage of a fraction of your computer's brainpower
- Modern computers have multiple-core CPUs but R only uses one of them 
- Unless you use parallel computing
- Sequential operations cannot be parallelized:
    - *Sequential operations:* If operation `B` depends on the result of operation `A` 
    - *Parallel operations:* If `B` is independent from the result of `A`

## Example: Matrix multiplication (sequential)

For example, take matrix multiplication repeated a number of times: 

```{r eval=FALSE}

# build matrices
m1 <- 2^10;
m2 <- 2^10;
n  <- 2^10;
z1 <- runif(m1*n); dim(z1) <- c(m1,n);
z2 <- runif(m2*n); dim(z2) <- c(m2,n);

# sequential execution of matrix mult
nopar <- list()
times <- 20
length(nopar) <- times
system.time( for( i in 1:times ){ nopar[[i]] <- z1 %*% t(z2) })
```

## Example: Matrix multiplication (parallel)

Several R libraries implement parallel computing in different ways, we'll use `doParallel`

```{r eval=FALSE}
library(doParallel)
# start cluster
ncores <- detectCores() - 1 # leave 1 core free
registerDoParallel(ncores)
# parallel execution of matrix mult
system.time( par <- foreach( i = 1:times ) %dopar% { z1 %*% t(z2) } )
# are results the same?
identical(par, nopar)
```

Gains will be larger as the initial fixed cost of distributing objects to all cores become smaller relative to the task. Be careful with memory!

## Learn more

- The vignette for the `foreach` package is probably the best place to start. 
- The vignette for `doParallel` is good to learn about CPU clusters in R, but provides few examples - The vignette for `parallel` has many more applications but may be too much for beginners. 

```{r, eval=FALSE}
vignette("foreach")
vignette("gettingstartedParallel", package="doParallel")
vignette("parallel",package="parallel")
```

## Writing Functions

```{r eval=FALSE}
myfunc <- function(arg1, arg2 = default2, ...){
  R instructions here
  return(value) 
}
```

- Function names must be a single word of characters and digits (first character must be a letter)
- Function arguments are passed on to the function body
- Optionally define default values
- Use `...` to pass additional arguments to a function within your function. 
- Brackets `{}` should enclose the function body 
- The function body is a set of R instructions to be run on each function call
- `return` indicates the value or object to be returned by the function

## Example:

```{r eval = FALSE}

sumofpowers <- function(x, power = 2, ...){
  out <- sum(x^power, ...)
  return(out)
}

sumofpowers(c(1, 2, 3), 3) # simple call

sumofpowers(1:10) # call with default values

sumofpowers(c(1, 2, NA, 3)) # call with missing value

# reordering arguments and passing arguments on to another function
sumofpowers(power = 3, x = c(1, 2, NA, 3), na.rm = TRUE) 

```

## Non-standard evaluation

- NSE lets a function take unquoted arguments 
- Easier to work with the function interactively, harder to write functions 
- Example: `subset`, no need to write `mtcars$mpg` or `"mpg"`:

```{r}
subset(mtcars, hp > 250)
```

## NSE fail

Using subset within a function is tricky:

```{r error=TRUE}
subsetmtcars <- function(condition){
  subset(mtcars, condition)
}
subsetmtcars(hp > 250)
```

## NSE with the  `subsitute` and `eval` functions

- `subset` tells the function to wait before evaluating the object 
- `eval` evaluates in the moment when the function can correctly interpret its value.

```{r}
subsetmtcars <- function(condition){
  condition <- substitute(condition)
  subset(mtcars, eval(condition))
}
subsetmtcars(hp > 250)
```

Important when programming functions with data.table!

## Sourcing scripts

Call a script with the function `source`:

```{r, eval=FALSE}
source("importFunctions.R")
```

Specify directories with `file.path`:

```{r, eval=FALSE}
source(file.path("home", "code", "importFunctions.R"))
```

You can also specify URLs:

```{r, eval=FALSE}
source("http://epidemos.es/epi2/libdemof.R")
```

Sourcing scripts is equivalent to opening the file and executing it.

## Debugging

- The function `debug` lets you single step through R functions
- RStudio includes a visual debugger including 
    - editor breakpoints
    - code and local environment visualization 
    - deep integration with traditional R debugging tools, such as `browser` and `debug`.
    - For details see [Debugging with RStudio](http://support.rstudio.com/hc/en-us/articles/200713843-Debugging-with-RStudio).

## Programming style guide

Good style is essential. Use common sense and **be consistent!**

- File names, variable names, function names should be meaningful.
- Use verbs for functions, nouns for function arguments
- Use underscores to separate words
- Line length: maximum 80 characters.
- Use indentation (spaces, no tabs)
- Place spaces 
    - around all binary operators (=, +, -, <-, etc.)
    - not before a comma, but always after a comma
    - before left parenthesis, except in a function call
    
## Programming style guide (cont.)
    
- Curly braces: first on same line, last on own line.
- Assignment: use `<-`, not `=`, except for function arguments
- Comments, comments, comments
- Raise errors in functions using `stop` or `stopifnot`.

Importing data
==============

```{r echo=FALSE}
opts_chunk$set(eval = FALSE)
```

## Delimited text files

- columns are explicitly delimited --- typically with ";" or "," or a tabulator (coded by `"\t"`). 
- The standard file is CSV (comma-separated values)
- The `read.table` function can import most of the delimited files you'll find
- Example: the [Demographic data of censal sections in Barcelona](http://opendata.bcn.cat/opendata/en/catalog/SOCIETAT_I_BENESTAR/taulamapscensal)

```{r}
### Import from url (can also import from downloaded file)
bcn_url <- "http://bit.ly/1MI6SaP" # I've shortened this link
censusBCN <- read.table(bcn_url, header=TRUE, sep=";")
```

## Using the *readr* package to import tabular data

Compared to the base import functions, the functions in this package: 

- have a consistent naming scheme for the parameters,
- are much faster for larger files, 
- do not convert strings into factors and 
- display a helpful progress bar if loading is going to take a while.

Download the Ageing Population file from the UK Open Data using the `read_delim` function (we could also use `read_csv`). 

```{r}
# Import
library(readr)
ap_url <- "http://opendata.s3.amazonaws.com/aging-population-2008.csv"
agingPopulation <- read_delim(ap_url, delim = ",")
```

## A speedy alternative: *fread*

The powerful `data.table` package also comes with a function that is much faster but slightly less flexible than `read.table`:

```{r}
library(data.table)
censusBCN <- fread(bcn_url)
agingPopulation <- fread(ap_url)
```

Much easier and way faster! Tables imported with `fread` are converted by default into *data.tables*

## Fixed-width files

- These files have no delimiters between columns, you'll need a description of the width of each column.
- Example from INE: [Survey on Human Resources in Science and Technology 2009](http://ine.es/en/prodyser/microdatos_en.htm). 
- Download both the [raw data](ftp://www.ine.es/temas/recurciencia/micro_recurciencia.zip) and [its metadata](ftp://www.ine.es/temas/recurciencia/disreg_recurciencia.xls)
- The standard R function to import this type of file is `read.fwf`
- You can use `read_fwf` from the readr package instead.

```{r}
## Metadata for the selected columns
rrhh_location <- file.path("~", "Downloads", "RRHH09.txt")
# RRHH09Widths <- c(6,2,4,2,4,1,4,4,4,1,1,2,2,2,2,2,1,1,...) # get from excel
fwfDataFrame <- read_fwf(
  rrhh_location, 
  col_positions = fwf_widths(RRHH09Widths)) 
```

## Importing Excel files

- Generally preferable: export your Excel files to text 
- If you want to import directly, the two packages that have worked best for me are readxl and gdata

```{r}
library(gdata)
# path to sample Excel file
xlsx <- file.path(path.package('gdata'), 'xls', 'ExampleExcelFile.xlsx')
sheetCount(xlsx) # check how many sheets it has
sheetNames(xlsx) # get their names
read.xls(xlsx, sheet = 2) # import one sheet
```

readxl has no external dependencies, it's easy to install and use on all OS's:

```{r}
library(readxl)
read_excel(path = xlsx, sheet = 2) 
```

## Importing SAS, Stata, and SPSS files

Use the following functions from the `haven` package:

- `read_sas`
- `read_spss`
- `read_dta`

Keep learning
=============

## Go deeper

- Interactive lessons **inside R** with [the Swirl package](http://swirlstats.com)
- Hadley Wickham [books](http://hadley.nz)
    - R for Data Science
    - ggplot2
    - Advanced R
    - R packages
- The [Datacamp](https://www.datacamp.com) online courses (esp. data.table)
- [R-bloggers](http://www.r-bloggers.com) to keep up with developments in the R community


